{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk\n",
    "import itkwidgets\n",
    "from itkwidgets import view\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "import tifffile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EmbedSeg.utils.create_dicts import create_test_configs_dict\n",
    "from EmbedSeg.test import begin_evaluating\n",
    "from glob import glob\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from EmbedSeg.utils.visualize import visualize\n",
    "import os\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the path to the evaluation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../data'\n",
    "project_name = 'Platynereis-ISH-Nuclei-CBG'\n",
    "print(\"Evaluation images shall be read from: {}\".format(os.path.join(data_dir, project_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify evaluation parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* `tta`: Setting this to True (default) would enable **test-time augmentation**\n",
    "* `ap_val`: This parameter (\"average precision value\") comes into action if ground truth segmentations exist for evaluation images, and allows to compare how good our predictions are versus the available ground truth segmentations.\n",
    "* `seed_thresh`: This parameter (\"seediness threshold\") allows considering only those pixels as potential instance-centres which have a seediness score greater than `seed_thresh`\n",
    "* `checkpoint_path`: This parameter provides the path to the trained model weights which you would like to use for evaluation. One could test the pretrained model (available at `'../../../pretrained_models/Platynereis-Nuclei-CBG/best_iou_model.pth'`) to get a quick glimpse on the results.\n",
    "* `save_dir`: This parameter specifies the path to the prediction instances. Equal to `static` by default.\n",
    "* `save_images`: If True, this saves predictions at `./static/predictions/` \n",
    "* `save_results`: If True, this saves results at `./static/results/`\n",
    "\n",
    "In the cell after this one, a `test_configs` dictionary is generated from the parameters specified here!\n",
    "<a id='checkpoint'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for the model trained by you\n",
    "# checkpoint_path = os.path.join('experiment', project_name+'-'+'demo', 'best_iou_model.pth')\n",
    "# if os.path.isfile('data_properties.json'): \n",
    "#     with open('data_properties.json') as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#         one_hot = data['one_hot']\n",
    "#         data_type = data['data_type']\n",
    "#         min_object_size = int(data['min_object_size'])\n",
    "#         foreground_weight = float(data['foreground_weight'])\n",
    "#         n_z, n_y, n_x = int(data['n_z']),int(data['n_y']), int(data['n_x'])\n",
    "#         pixel_size_z_microns, pixel_size_y_microns, pixel_size_x_microns = float(data['pixel_size_z_microns']), float(data['pixel_size_y_microns']), float(data['pixel_size_x_microns']) \n",
    "#         avg_background_intensity = float(data['avg_background_intensity'])\n",
    "\n",
    "# use the following for the pretrained model weights\n",
    "checkpoint_path = os.path.join('../../../pretrained_models', project_name, 'best_iou_model.pth')\n",
    "if os.path.isfile(os.path.join('../../../pretrained_models', project_name,'data_properties.json')): \n",
    "    with open(os.path.join('../../../pretrained_models', project_name, 'data_properties.json')) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        one_hot = data['one_hot']\n",
    "        data_type = data['data_type']\n",
    "        min_object_size = int(data['min_object_size'])\n",
    "        foreground_weight = float(data['foreground_weight'])\n",
    "        n_z, n_y, n_x = int(data['n_z']),int(data['n_y']), int(data['n_x'])\n",
    "        pixel_size_z_microns, pixel_size_y_microns, pixel_size_x_microns = float(data['pixel_size_z_microns']), float(data['pixel_size_y_microns']), float(data['pixel_size_x_microns']) \n",
    "        avg_background_intensity = float(data['avg_background_intensity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ℹ️ Setting `tta=True` would give better results but would take longer to compute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta = True\n",
    "ap_val = 0.5\n",
    "seed_thresh = 0.90\n",
    "save_dir = './static'\n",
    "save_images = True\n",
    "save_results = True\n",
    "normalization_factor = 65535 if data_type=='16-bit' else 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Trained model weights found at : {}\".format(checkpoint_path))\n",
    "else:\n",
    "    print(\"Trained model weights were not found at the specified location!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `test_configs` dictionary from the above-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_configs = create_test_configs_dict(data_dir = os.path.join(data_dir, project_name),\n",
    "                                        checkpoint_path = checkpoint_path,\n",
    "                                        tta = tta, \n",
    "                                        ap_val = ap_val,\n",
    "                                        seed_thresh = seed_thresh, \n",
    "                                        min_object_size = min_object_size, \n",
    "                                        save_images = save_images,\n",
    "                                        save_results = save_results,\n",
    "                                        save_dir = save_dir,\n",
    "                                        normalization_factor = normalization_factor,\n",
    "                                        one_hot = one_hot,\n",
    "                                        n_z = n_z,\n",
    "                                        n_y = n_y,\n",
    "                                        n_x = n_x,\n",
    "                                        anisotropy_factor = pixel_size_z_microns/pixel_size_x_microns,\n",
    "                                        name = '3d',\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `verbose` to True shows you Average Precision at IOU threshold specified by `ap_val` above for each individual image. The higher this score is, the better the network has learnt to perform instance segmentation on these unseen images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_evaluating(test_configs, verbose = False, avg_bg = avg_background_intensity/normalization_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "  Common causes for a low score/error is: <br>\n",
    "    1. Accessing the model weights at the wrong location. Simply editing the <b> checkpoint_path</b> would fix the issue. <br>\n",
    "    2. At times, you would notice an improved performance by lowering <b><a href=\"#checkpoint\"> seed_thresh</a></b> from 0.90 (default) to say 0.80. <br>\n",
    "    3. CUDA error: out of memory - ensure that you shutdown <i>02-train.ipynb</i> notebook before running this notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the `itkwidgets` to first display any one of the evaluation images and then display the corresponding prediction by the model. Please feel free to change the `index` to look at other predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(save_images):\n",
    "    prediction_file_names = sorted(glob(os.path.join(save_dir,'predictions','*.tif')))\n",
    "    ground_truth_file_names = sorted(glob(os.path.join(save_dir,'ground-truth','*.tif')))\n",
    "    image_file_names = sorted(glob(os.path.join(save_dir, 'images','*.tif')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "print(\"Image filename is {} and index is {}\".format(os.path.basename(image_file_names[index]), index))\n",
    "\n",
    "image = normalization_factor*tifffile.imread(image_file_names[index])\n",
    "prediction = tifffile.imread(prediction_file_names[index])\n",
    "\n",
    "image_itk =itk.GetImageFromArray(image)\n",
    "image_itk.SetSpacing([pixel_size_x_microns, pixel_size_y_microns, pixel_size_z_microns])\n",
    "prediction_itk =itk.GetImageFromArray(prediction)\n",
    "prediction_itk.SetSpacing([pixel_size_x_microns, pixel_size_y_microns, pixel_size_z_microns])\n",
    "view(image_itk, label_image=prediction_itk, cmap=itkwidgets.cm.BrBG, annotations=False, vmax=800, ui_collapsed=True, background=(192, 192, 192))\n",
    "#embed_minimal_html('export_'+str(index)+'.html', views=viewer, title='Widgets export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print(\"Image filename is {} and index is {}\".format(os.path.basename(image_file_names[index]), index))\n",
    "\n",
    "\n",
    "image = normalization_factor*tifffile.imread(image_file_names[index])\n",
    "prediction = tifffile.imread(prediction_file_names[index])\n",
    "\n",
    "image_itk =itk.GetImageFromArray(image)\n",
    "image_itk.SetSpacing([pixel_size_x_microns, pixel_size_y_microns, pixel_size_z_microns])\n",
    "prediction_itk =itk.GetImageFromArray(prediction)\n",
    "prediction_itk.SetSpacing([pixel_size_x_microns, pixel_size_y_microns, pixel_size_z_microns])\n",
    "view(image_itk, label_image=prediction_itk, cmap=itkwidgets.cm.BrBG, annotations=False, vmax=800, ui_collapsed=True, background=(192, 192, 192))\n",
    "#embed_minimal_html('export_'+str(index)+'.html', views=viewer, title='Widgets export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
